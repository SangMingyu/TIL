{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 텍스트 마이닝 기본문법\n",
        ""
      ],
      "metadata": {
        "id": "q5EeWHJoHKiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문장 토큰화\n",
        "- 파이썬 머신러닝 완벽 가이드 (p.492)"
      ],
      "metadata": {
        "id": "mC7l4F6GHRbr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfi0txN-GmN-",
        "outputId": "072d2b78-1ae5-48ce-f6d8-79cf9fc96d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from nltk import sent_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt') # 마침표, 개행 문자 관련 데이터 세트를 다운로드 한다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Document = 문서\n",
        "text_sample = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
        "               You can see it out your window or on your television. \\\n",
        "               You feel it when you go to work, or go to church or pay your taxes.'\n",
        "\n",
        "sentences = sent_tokenize(text=text_sample)\n",
        "print(type(sentences))\n",
        "print(len(sentences))\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Nd4b5rKHoj8",
        "outputId": "b5b2f7b4-496f-4954-c39a-ac493cd54080"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "3\n",
            "['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단어 토큰화\n",
        "- 문장을 각각의 단어로 다시 토큰화함"
      ],
      "metadata": {
        "id": "d4I-8ijsIMgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "sentence = \"The Matrix is everywhere its all around us, here even in this room.\"\n",
        "words = word_tokenize(sentence)\n",
        "print(type(words))\n",
        "print(len(words))\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yog_kYNCH4ZT",
        "outputId": "d63a25c7-bb93-4d59-b6e6-363033af2fad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "15\n",
            "['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문서를 단어로 토큰화하는 함수\n",
        "- 문서 => 문장 => 단어 ====> 단어 뭉치(?)로 묶자"
      ],
      "metadata": {
        "id": "CE07S4GBIwQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, sent_tokenize\n",
        "\n",
        "# 여러개의 문장으로 된 입력 데이터를 문장별로 단어 토큰화하는 함수\n",
        "def tokenize_text(text):\n",
        "\n",
        "  # 문장별로 분리 토큰\n",
        "  sentences = sent_tokenize(text) # 3개의 리스트\n",
        "\n",
        "  # 각 문장을 단어별로 토큰화\n",
        "  word_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
        "  return word_tokens\n",
        "\n",
        "# 문서를 단어별로 토큰화 수행\n",
        "word_tokens = tokenize_text(text_sample)\n",
        "print(type(word_tokens),len(word_tokens))\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2J-XqinIq5g",
        "outputId": "63678c11-a2f7-4a1a-d802-016be973827a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 3\n",
            "[['The', 'Matrix', 'is', 'everywhere', 'its', 'all', 'around', 'us', ',', 'here', 'even', 'in', 'this', 'room', '.'], ['You', 'can', 'see', 'it', 'out', 'your', 'window', 'or', 'on', 'your', 'television', '.'], ['You', 'feel', 'it', 'when', 'you', 'go', 'to', 'work', ',', 'or', 'go', 'to', 'church', 'or', 'pay', 'your', 'taxes', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_sample = \"“I have withdrawn from the musical Tiananmen,” Piser said in a brief signed statement on Instagram. Piser was on tour performing hit Broadway songs in the Chinese metropolis of Shanghai when he made the announcement, according to his Instagram posts and Chinese state media reports. In China, the Tiananmen Square pro-democracy protests, which swept Beijing and dozens of other Chinese cities in 1989 – and ended in a bloody military crackdown that cost the lives of hundreds, if not thousands, of protesters – remain a major political taboo.\"\n",
        "word_tokens = tokenize_text(text_sample)\n",
        "print(type(word_tokens),len(word_tokens))\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8TRTWiKJw4l",
        "outputId": "e2d3de72-6fae-4d64-d1d5-a3c2c59789d7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 3\n",
            "[['“', 'I', 'have', 'withdrawn', 'from', 'the', 'musical', 'Tiananmen', ',', '”', 'Piser', 'said', 'in', 'a', 'brief', 'signed', 'statement', 'on', 'Instagram', '.'], ['Piser', 'was', 'on', 'tour', 'performing', 'hit', 'Broadway', 'songs', 'in', 'the', 'Chinese', 'metropolis', 'of', 'Shanghai', 'when', 'he', 'made', 'the', 'announcement', ',', 'according', 'to', 'his', 'Instagram', 'posts', 'and', 'Chinese', 'state', 'media', 'reports', '.'], ['In', 'China', ',', 'the', 'Tiananmen', 'Square', 'pro-democracy', 'protests', ',', 'which', 'swept', 'Beijing', 'and', 'dozens', 'of', 'other', 'Chinese', 'cities', 'in', '1989', '–', 'and', 'ended', 'in', 'a', 'bloody', 'military', 'crackdown', 'that', 'cost', 'the', 'lives', 'of', 'hundreds', ',', 'if', 'not', 'thousands', ',', 'of', 'protesters', '–', 'remain', 'a', 'major', 'political', 'taboo', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_sample = \"삼성전자와 LG전자가 스마트홈 플랫폼에서 손을 잡았다. 8월 31일 관련업계에 따르면 삼성전자와 LG전자는 올해 안에 스마트홈 플랫폼으로 양사 가전을 연동하는 것을 목표로 협력하고 있다. 연내 삼성전자와 LG전자의 가전 관리용 전용 앱을 통해 양사는 물론 다른 회사의 가전제품까지 무선 및 원격으로 작동하거나 제어할 수 있도록 하겠다는 계획이다. 두 회사는 ‘홈 커넥티비티 얼라이언스(HCA)’ 표준을 설계·적용해 타사의 브랜드 가전제품을 자사 앱에서 제어할 수 있도록 지원하는 것으로 알려졌따. 지난해 설립된 HCA는 삼성전자와 LG전자, 튀르키예의 베스텔, 일본 샤프를 비롯한 15개 회원사가 참여하고 있다. 15개사 가전 관리용 앱으로 다른 회원사의 가전제품을 제어하는 표준 기술을 개발 중이다. 삼성전자와 LG전자는 HCA 의장사로 이 같은 ‘스마트홈 가전 동맹’을 주도하고 있다. 당장 9월 가전 관리용 전용 앱인 삼성전자의 ‘스마트싱스’로 베스텔, 샤프 등 글로벌 가전업체 제품을 제어할 수 있게 된다. 연내에는 LG전자 가전제품도 작동할 수 있게 된다. 예컨대 소비자들은 삼성전자 스마트싱스 앱으로 이와 연결된 LG전자 TV, 세탁기 등의 가전을 작동하거나 설정을 조작할 수 있다. LG전자의 가전 관리용 전용 앱 ‘LG 씽큐’로도 올해 안에 삼성전자 가전제품을 조작하는 게 가능해진다. 베스텔 가전제품을 연동하는 방안도 추진하고 있다. 삼성전자와 LG전자의 ‘스마트홈 플랫폼 동맹’은 올해 한국 미국 유럽 등 글로벌 주요 시장에서 순차적으로 이어질 계획이다. 대상 제품은 냉장고 세탁기 에어컨 건조기 식기세척기 오븐 로봇청소기 TV 공기청정기 등이다. 양사는 앞으로 연동 대상 제품을 확대해 나갈 계획이다.\"\n",
        "word_tokens = tokenize_text(text_sample)\n",
        "print(type(word_tokens),len(word_tokens))\n",
        "print(word_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4j3huSXKax2",
        "outputId": "343fb304-0b02-4efc-bcba-22c29fcf3868"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 15\n",
            "[['삼성전자와', 'LG전자가', '스마트홈', '플랫폼에서', '손을', '잡았다', '.'], ['8월', '31일', '관련업계에', '따르면', '삼성전자와', 'LG전자는', '올해', '안에', '스마트홈', '플랫폼으로', '양사', '가전을', '연동하는', '것을', '목표로', '협력하고', '있다', '.'], ['연내', '삼성전자와', 'LG전자의', '가전', '관리용', '전용', '앱을', '통해', '양사는', '물론', '다른', '회사의', '가전제품까지', '무선', '및', '원격으로', '작동하거나', '제어할', '수', '있도록', '하겠다는', '계획이다', '.'], ['두', '회사는', '‘', '홈', '커넥티비티', '얼라이언스', '(', 'HCA', ')', '’', '표준을', '설계·적용해', '타사의', '브랜드', '가전제품을', '자사', '앱에서', '제어할', '수', '있도록', '지원하는', '것으로', '알려졌따', '.'], ['지난해', '설립된', 'HCA는', '삼성전자와', 'LG전자', ',', '튀르키예의', '베스텔', ',', '일본', '샤프를', '비롯한', '15개', '회원사가', '참여하고', '있다', '.'], ['15개사', '가전', '관리용', '앱으로', '다른', '회원사의', '가전제품을', '제어하는', '표준', '기술을', '개발', '중이다', '.'], ['삼성전자와', 'LG전자는', 'HCA', '의장사로', '이', '같은', '‘', '스마트홈', '가전', '동맹', '’', '을', '주도하고', '있다', '.'], ['당장', '9월', '가전', '관리용', '전용', '앱인', '삼성전자의', '‘', '스마트싱스', '’', '로', '베스텔', ',', '샤프', '등', '글로벌', '가전업체', '제품을', '제어할', '수', '있게', '된다', '.'], ['연내에는', 'LG전자', '가전제품도', '작동할', '수', '있게', '된다', '.'], ['예컨대', '소비자들은', '삼성전자', '스마트싱스', '앱으로', '이와', '연결된', 'LG전자', 'TV', ',', '세탁기', '등의', '가전을', '작동하거나', '설정을', '조작할', '수', '있다', '.'], ['LG전자의', '가전', '관리용', '전용', '앱', '‘', 'LG', '씽큐', '’', '로도', '올해', '안에', '삼성전자', '가전제품을', '조작하는', '게', '가능해진다', '.'], ['베스텔', '가전제품을', '연동하는', '방안도', '추진하고', '있다', '.'], ['삼성전자와', 'LG전자의', '‘', '스마트홈', '플랫폼', '동맹', '’', '은', '올해', '한국', '미국', '유럽', '등', '글로벌', '주요', '시장에서', '순차적으로', '이어질', '계획이다', '.'], ['대상', '제품은', '냉장고', '세탁기', '에어컨', '건조기', '식기세척기', '오븐', '로봇청소기', 'TV', '공기청정기', '등이다', '.'], ['양사는', '앞으로', '연동', '대상', '제품을', '확대해', '나갈', '계획이다', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stopwords 제거\n",
        "- 불용어 : 분석에 큰 의미가 없는 단어\n",
        "- p.495"
      ],
      "metadata": {
        "id": "eMHe4KFIKpck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqKCVhZyKwN4",
        "outputId": "af02c3c9-eeb5-4710-87b7-29fd7f9739c9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"영어 불용어 갯수:\", len(nltk.corpus.stopwords.words('english')))\n",
        "print(nltk.corpus.stopwords.words('english')[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ow1GRGdK8Nu",
        "outputId": "a8cf8788-bd82-44eb-95f0-d377fc084b6c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 불용어 갯수: 179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 불용어 제거"
      ],
      "metadata": {
        "id": "v2U5TvxeLjHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_sample = 'The Matrix is everywhere its all around us, here even in this room. \\\n",
        "               You can see it out your window or on your television. \\\n",
        "               You feel it when you go to work, or go to church or pay your taxes.'\n",
        "word_tokens = tokenize_text(text_sample)\n",
        "\n",
        "# 특정 도메인에서 분석을 하려고 함\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "stopwords = stopwords + ['everywhere', 'us'] # 이런식으로 제거할 필요없는 단어를 추가해서 단어를 날림\n",
        "\n",
        "all_tokens = []\n",
        "# 위 예제의 3개의 문장별로 얻은 word_tokens list 에 대해 stop word 제거 Loop\n",
        "for sentence in word_tokens:\n",
        "    filtered_words=[]\n",
        "    # 개별 문장별로 tokenize된 sentence list에 대해 stop word 제거 Loop\n",
        "    for word in sentence:\n",
        "        #소문자로 모두 변환합니다.\n",
        "        word = word.lower()\n",
        "        # tokenize 된 개별 word가 stop words 들의 단어에 포함되지 않으면 word_tokens에 추가\n",
        "        if word not in stopwords:\n",
        "            filtered_words.append(word)\n",
        "    all_tokens.append(filtered_words)\n",
        "\n",
        "print(all_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5UnRC17LMCe",
        "outputId": "e4fe0eb5-c828-436e-ef95-d22094cf4ae3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['matrix', 'around', ',', 'even', 'room', '.'], ['see', 'window', 'television', '.'], ['feel', 'go', 'work', ',', 'go', 'church', 'pay', 'taxes', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 어근 추출"
      ],
      "metadata": {
        "id": "ayqtJ1W7OGJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "print(stemmer.stem('working'),stemmer.stem('works'),stemmer.stem('worked'))\n",
        "print(stemmer.stem('amusing'),stemmer.stem('amuses'),stemmer.stem('amused'))\n",
        "print(stemmer.stem('happier'),stemmer.stem('happiest'))\n",
        "print(stemmer.stem('fancier'),stemmer.stem('fanciest'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3BtjoMGLtx8",
        "outputId": "b05cec1b-cca3-4e2f-e2ae-dfb3effdda2d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "work work work\n",
            "amus amus amus\n",
            "happy happiest\n",
            "fant fanciest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemma = WordNetLemmatizer()\n",
        "print(lemma.lemmatize('amusing','v'),lemma.lemmatize('amuses','v'),lemma.lemmatize('amused','v'))\n",
        "print(lemma.lemmatize('happier','a'),lemma.lemmatize('happiest','a'))\n",
        "print(lemma.lemmatize('fancier','a'),lemma.lemmatize('fanciest','a'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23r1OF-eOPQ3",
        "outputId": "737d0019-31a3-46a4-8bb3-8325686923de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amuse amuse amuse\n",
            "happy happy\n",
            "fancy fancy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 불러오기"
      ],
      "metadata": {
        "id": "tMe1whKDOWdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmVQHttROStX",
        "outputId": "0272b36c-9e8d-4f64-af70-e7d06fc36df6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "DATA_PATH = '/content/drive/MyDrive/Colab Notebooks/text_mining/'\n",
        "\n",
        "# p.520\n",
        "review_df = pd.read_csv(DATA_PATH + './labeledTrainData.tsv', header=0, sep=\"\\t\", quoting=3)\n",
        "review_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "JWK9C_BPVlD-",
        "outputId": "976fc5ce-fe58-4d77-d6a4-f96c9e84d3d8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  sentiment                                             review\n",
              "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6e9ef15-26f4-4cb4-8e1a-8a9edfba67cf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6e9ef15-26f4-4cb4-8e1a-8a9edfba67cf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6e9ef15-26f4-4cb4-8e1a-8a9edfba67cf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6e9ef15-26f4-4cb4-8e1a-8a9edfba67cf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_df['review'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "QKeLdNtxW6d_",
        "outputId": "774723bc-32f2-40b3-bcc7-515c2a4f9083"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텍스트 전처리"
      ],
      "metadata": {
        "id": "okxum22iWh1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "review_df['review'] = review_df['review'].str.replace('<br />', ' ')\n",
        "review_df['review'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "iPefTV0WV7Db",
        "outputId": "82dc860c-6150-42c3-df8a-f46b9e01f008"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.  Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.  The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.  Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.  Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 영어 문자열이 아닌 모든 문자는 공백으로 변환\n",
        "review_df['review'] = review_df['review'].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x))\n",
        "review_df['review'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "8zN50HhlXK-v",
        "outputId": "7c78da70-a8a5-483d-812b-c8a7278b5f67"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' With all this stuff going down at the moment with MJ i ve started listening to his music  watching the odd documentary here and there  watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJ s feeling towards the press and also the obvious message of drugs are bad m kay   Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring  Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him   The actual feature film bit when it finally starts is only on for    minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord  Why he wants MJ dead so bad is beyond me  Because MJ overheard his plans  Nah  Joe Pesci s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno  maybe he just hates MJ s music   Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence  Also  the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene   Bottom line  this movie is for people who like MJ on one level or another  which i think is most people   If not  then stay away  It does try and give off a wholesome message and ironically MJ s bestest buddy in this movie is a girl  Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty  Well  with all the attention i ve gave this subject    hmmm well i don t know because people can be different behind closed doors  i know this for a fact  He is either an extremely nice but stupid guy or one of the most sickest liars  I hope he is not the latter  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 훈련 데이터, 테스트 데이터 분리"
      ],
      "metadata": {
        "id": "33UKR40eYsru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "class_df = review_df['sentiment'] # Y : 1은 긍정, 0은 부정\n",
        "feature_df = review_df.drop(['id', 'sentiment'], axis = 1) # reivew만 남음\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    feature_df, class_df, test_size = 0.3, random_state = 156\n",
        ")\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6jIFzKrXwv7",
        "outputId": "d999eeeb-b156-455c-d3bd-716d83429969"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17500, 1), (7500, 1), (17500,), (7500,))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "cUvg9V5eZvDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('cnt_vect', CountVectorizer(stop_words = 'english', ngram_range = (1, 2))),\n",
        "    ('lr_clf', LogisticRegression(solver = 'liblinear', C = 10))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train['review'], y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "QdQ43ZieZfr4",
        "outputId": "84a04c5d-6f12-4a43-94b8-8ba355435628"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('cnt_vect',\n",
              "                 CountVectorizer(ngram_range=(1, 2), stop_words='english')),\n",
              "                ('lr_clf', LogisticRegression(C=10, solver='liblinear'))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cnt_vect&#x27;,\n",
              "                 CountVectorizer(ngram_range=(1, 2), stop_words=&#x27;english&#x27;)),\n",
              "                (&#x27;lr_clf&#x27;, LogisticRegression(C=10, solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cnt_vect&#x27;,\n",
              "                 CountVectorizer(ngram_range=(1, 2), stop_words=&#x27;english&#x27;)),\n",
              "                (&#x27;lr_clf&#x27;, LogisticRegression(C=10, solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2), stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pipeline.predict(X_test['review'])\n",
        "pred_probs = pipeline.predict_proba(X_test['review'])[:, 1]\n",
        "\n",
        "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test ,pred),\n",
        "                                         roc_auc_score(y_test, pred_probs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OdZW_tNazrD",
        "outputId": "4dee5f7a-890f-453d-ae71-131458f97e6e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도는 0.8861, ROC-AUC는 0.9503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- TF-IDF 활용해서 측정"
      ],
      "metadata": {
        "id": "VDHJ3h-3biKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('cnt_vect', TfidfVectorizer(stop_words = 'english', ngram_range = (1, 2))),\n",
        "    ('lr_clf', LogisticRegression(solver = 'liblinear', C = 10))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train['review'], y_train)\n",
        "\n",
        "pred = pipeline.predict(X_test['review'])\n",
        "pred_probs = pipeline.predict_proba(X_test['review'])[:, 1]\n",
        "\n",
        "print('예측 정확도는 {0:.4f}, ROC-AUC는 {1:.4f}'.format(accuracy_score(y_test ,pred),\n",
        "                                         roc_auc_score(y_test, pred_probs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjMoROz_bMA1",
        "outputId": "447ea768-4938-4e63-f113-bca1a14ba6cb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "예측 정확도는 0.8936, ROC-AUC는 0.9598\n",
            "24 s ± 1.96 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(review_df['review'])\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmyxjTehb10L",
        "outputId": "b87ca6bb-7209-4095-d2ca-300afe84172b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 73246)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(review_df['review'])\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYshSDFic6ni",
        "outputId": "dfa4deca-5446-4b4d-d3a4-01c909841e19"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 73246)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgIpkevjc_UR",
        "outputId": "d6a92c14-813f-408d-c198-47d0a78b058e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 71786)\t4\n",
            "  (0, 1558)\t4\n",
            "  (0, 65032)\t11\n",
            "  (0, 62272)\t1\n",
            "  (0, 26679)\t3\n",
            "  (0, 18635)\t1\n",
            "  (0, 3639)\t2\n",
            "  (0, 64811)\t19\n",
            "  (0, 42129)\t1\n",
            "  (0, 41901)\t11\n",
            "  (0, 69374)\t2\n",
            "  (0, 61392)\t1\n",
            "  (0, 37621)\t1\n",
            "  (0, 65592)\t9\n",
            "  (0, 29773)\t3\n",
            "  (0, 43124)\t2\n",
            "  (0, 70705)\t1\n",
            "  (0, 45213)\t1\n",
            "  (0, 18164)\t1\n",
            "  (0, 29351)\t1\n",
            "  (0, 2147)\t10\n",
            "  (0, 64904)\t1\n",
            "  (0, 70699)\t2\n",
            "  (0, 71838)\t1\n",
            "  (0, 42364)\t2\n",
            "  :\t:\n",
            "  (0, 66844)\t1\n",
            "  (0, 63836)\t1\n",
            "  (0, 21498)\t1\n",
            "  (0, 27026)\t1\n",
            "  (0, 48796)\t1\n",
            "  (0, 71002)\t2\n",
            "  (0, 3772)\t1\n",
            "  (0, 25678)\t1\n",
            "  (0, 62417)\t1\n",
            "  (0, 29861)\t1\n",
            "  (0, 18346)\t1\n",
            "  (0, 9203)\t1\n",
            "  (0, 5208)\t1\n",
            "  (0, 17121)\t1\n",
            "  (0, 5517)\t1\n",
            "  (0, 11758)\t1\n",
            "  (0, 18459)\t1\n",
            "  (0, 22262)\t1\n",
            "  (0, 19924)\t1\n",
            "  (0, 22137)\t1\n",
            "  (0, 62320)\t1\n",
            "  (0, 58569)\t1\n",
            "  (0, 37217)\t1\n",
            "  (0, 30273)\t1\n",
            "  (0, 36529)\t1\n"
          ]
        }
      ]
    }
  ]
}